# ğŸ§ª Assignment: Variational Autoencoder with Encoder-Decoder Architectures

## ğŸ“Œ Objective

Explore the effect of using **encoder-decoder architectures** within a **Variational Autoencoder (VAE)** framework. This week, we will:
- Build a standard VAE.
- Modify the encoder and/or decoder to follow an encoder-decoder sub-structure.
- Compare reconstruction quality and latent space representations.
- Analyze and report which structure works best.

---

## ğŸ§± VAE Architecture Overview

A **Variational Autoencoder (VAE)** normally has two main components:
- **Encoder**: Compresses the input data into a latent distribution.
- **Decoder**: Samples from this latent space to reconstruct the data.

### â• Extension: Encoder-Decoder Inside VAE

An **encoder-decoder architecture** has layers with:
- Decreasing size â†’ bottleneck â†’ increasing size.
- Think of it as downsampling then upsampling within a component (not just across encoder and decoder).

---

## ğŸ”§ Task A â€“ Implementing VAE Variants

You will implement **four VAE variants**:

### A.1 â€“ Basic VAE (Baseline)
- Standard VAE with:
  - Encoder â†’ [200, 100, 50]
  - Latent space
  - Decoder â†’ [50, 100, 200]

### A.2 â€“ Encoder Side as Encoder-Decoder
- Replace the **encoder** with an encoder-decoder structure.
  - Downsample â†’ Upsample â†’ Latent
- Decoder remains the same.

### A.3 â€“ Decoder Side as Encoder-Decoder
- Encoder is standard.
- Replace the **decoder** with an encoder-decoder structure:
  - Latent â†’ Downsample â†’ Upsample â†’ Output

### A.4 â€“ Both Sides as Encoder-Decoder
- Both encoder and decoder use encoder-decoder sub-architectures.

---

## ğŸ“Š Task B â€“ Evaluation and Comparison

### B.1 â€“ Metrics
- Use metrics like:
  - Reconstruction Loss (MSE or BCE)
  - KL Divergence
  - Total VAE Loss

### B.2 â€“ Visual Output
- Display 10 reconstructed images for each variant.

### B.3 â€“ Analysis
- Write a brief report (~200 words):
  - Which architecture performed best and why?
  - Trade-offs (e.g., training time, complexity, overfitting).
  - Effect on reconstruction quality and latent representations.

---

## ğŸ’¡ Hints and Resources

- Use TensorFlow/Keras for quick prototyping.
- You can choose **Dense** or **Conv** layers (or both).
- Examples of encoder-decoder architectures:
  - [SegNet](https://mi.eng.cam.ac.uk/projects/segnet/)
  - U-Net
  - Autoencoders with symmetrical structures

---

## ğŸ“ Submission Guidelines

- Submit:
  - `vae_variants.ipynb` or `vae_variants.py`, containing the variations of autoencoders
  - `assignment.md` (this file, with Part B filled in)


---

Feel free to reach out on the discussion board for any clarifications or troubleshooting help.
