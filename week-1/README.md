# Here we go
This week, we’ll be diving into the foundations of neural networks, starting from the basics. We'll use simple math concepts to build an understanding of how models learn, beginning with linear regression as a stepping stone.
From there, we’ll explore how these ideas extend to neural networks, focusing on core components like layers, activations, and training processes. We'll also introduce convolutional neural networks (CNNs), which is a powerful type of neural network especially effective for image data.

By the end of the week, you should have a solid grasp of:
* Linear regression and gradient descent
* Basic architecture of neural networks
* The intuition behind CNNs and how they work

Resources:
* ML specialization by Andrew Ng: [youtube](https://www.youtube.com/playlist?list=PLkDaE6sCZn6FNC6YRfRQc_FbeQrF8BwGI) 
* Cover till chapter 5: [3b1b](https://www.3blue1brown.com/topics/neural-networks)
* Convolutional Neural Nets [CNNs](https://www.youtube.com/watch?v=LxfUGhug-iQ)
* Or also CNNs: refer to the first 12 videos of [this](https://www.youtube.com/playlist?list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF)
* Additional: [Textbook](https://www.deeplearningbook.org/)
