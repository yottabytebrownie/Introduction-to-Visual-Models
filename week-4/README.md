# 📦 Week 4: Generative Adversarial Networks (GANs)

This week focuses on **Generative Adversarial Networks (GANs)** — one of the most fascinating and powerful ideas in modern deep learning. You will explore how GANs work, understand their intuition, and implement them using TensorFlow.

---

## 🎯 Objectives

By the end of this week, you will:

- Understand the basic intuition and architecture of GANs.
- Explore how GANs differ from VAEs and other generative models.
- Learn about the discriminator-generator training loop.
- Build a simple GAN using TensorFlow/Keras.
- Understand common challenges like mode collapse and instability.

---

## 🧠 Key Concepts

- **Discriminator vs. Generator**
- **Adversarial Training**
- **Latent Space Sampling**
- **Loss Functions in GANs**
- **Training Dynamics & Stability**

---

## 📚 Learning Materials

### 📝 Theory & Concepts

- 📘 [**Basic Overview of GANs – IBM**](https://www.ibm.com/blogs/research/2020/06/gan/)
- 📚 [IBM YT](https://www.youtube.com/watch?v=TpMIssRdhco)
- 🎥 [**Intuition Behind GANs – Computerphile**](https://www.youtube.com/watch?v=Sw9r8CL98N0)
- 📕 [**Comprehensive History of Deep Generative Modelling** (Paper)]([https://arxiv.org/abs/1906.01529](https://docs.google.com/viewerng/viewer?url=https://arxiv.org/pdf/2103.05180))

---

### 🎓 MIT 6.S191 Lecture – Deep Generative Modelling

- 📺 [**Guide to Deep Generative Modelling (MIT 6.S191)**](https://www.youtube.com/watch?v=Dmm4UG-6jxA)
  - VAEs (0:00:00 to 0:40:00)
  - GANs (0:40:00 to 0:55:00)

---

## 🔧 Hands-On Tutorials

### 📦 GANs Implementation

- 💻 [**Google GANs Tutorial (Colab)**](https://developers.google.com/machine-learning/gan)
- 💡 [**TensorFlow GAN Tutorial**](https://www.tensorflow.org/tutorials/generative/dcgan)
- 🎥 [**Video Tutorial on GANs (YouTube)**](https://www.youtube.com/watch?v=8L11aMN5KY8)

---

## 🧪 This Week’s Focus

You will build a **DCGAN (Deep Convolutional GAN)** to generate realistic images from random noise using the Fashion-MNIST or CIFAR-10 dataset. You'll also experiment with:

- Adjusting the architecture of the generator/discriminator
- Monitoring training progress visually
- Exploring different latent vector dimensions

---

