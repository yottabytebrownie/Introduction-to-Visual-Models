# ğŸ“¦ Week 4: Generative Adversarial Networks (GANs)

This week focuses on **Generative Adversarial Networks (GANs)** â€” one of the most fascinating and powerful ideas in modern deep learning. You will explore how GANs work, understand their intuition, and implement them using TensorFlow.

---

## ğŸ¯ Objectives

By the end of this week, you will:

- Understand the basic intuition and architecture of GANs.
- Explore how GANs differ from VAEs and other generative models.
- Learn about the discriminator-generator training loop.
- Build a simple GAN using TensorFlow/Keras.
- Understand common challenges like mode collapse and instability.

---

## ğŸ§  Key Concepts

- **Discriminator vs. Generator**
- **Adversarial Training**
- **Latent Space Sampling**
- **Loss Functions in GANs**
- **Training Dynamics & Stability**

---

## ğŸ“š Learning Materials

### ğŸ“ Theory & Concepts

- ğŸ“˜ [**Basic Overview of GANs â€“ IBM**](https://www.ibm.com/blogs/research/2020/06/gan/)
- ğŸ“š [IBM YT](https://www.youtube.com/watch?v=TpMIssRdhco)
- ğŸ¥ [**Intuition Behind GANs â€“ Computerphile**](https://www.youtube.com/watch?v=Sw9r8CL98N0)
- ğŸ“• [**Comprehensive History of Deep Generative Modelling** (Paper)]([https://arxiv.org/abs/1906.01529](https://docs.google.com/viewerng/viewer?url=https://arxiv.org/pdf/2103.05180))

---

### ğŸ“ MIT 6.S191 Lecture â€“ Deep Generative Modelling

- ğŸ“º [**Guide to Deep Generative Modelling (MIT 6.S191)**](https://www.youtube.com/watch?v=Dmm4UG-6jxA)
  - VAEs (0:00:00 to 0:40:00)
  - GANs (0:40:00 to 0:55:00)

---

## ğŸ”§ Hands-On Tutorials

### ğŸ“¦ GANs Implementation

- ğŸ’» [**Google GANs Tutorial (Colab)**](https://developers.google.com/machine-learning/gan)
- ğŸ’¡ [**TensorFlow GAN Tutorial**](https://www.tensorflow.org/tutorials/generative/dcgan)
- ğŸ¥ [**Video Tutorial on GANs (YouTube)**](https://www.youtube.com/watch?v=8L11aMN5KY8)

---

## ğŸ§ª This Weekâ€™s Focus

You will build a **DCGAN (Deep Convolutional GAN)** to generate realistic images from random noise using the Fashion-MNIST or CIFAR-10 dataset. You'll also experiment with:

- Adjusting the architecture of the generator/discriminator
- Monitoring training progress visually
- Exploring different latent vector dimensions

---

